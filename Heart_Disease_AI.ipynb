{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age  sex        cp  trestbps      chol  fbs  restecg   thalach  exang  \\\n",
      "0  0.708333  1.0  0.000000  0.481132  0.244292  1.0      1.0  0.603053    0.0   \n",
      "1  0.791667  1.0  1.000000  0.622642  0.365297  0.0      1.0  0.282443    1.0   \n",
      "2  0.791667  1.0  1.000000  0.245283  0.235160  0.0      1.0  0.442748    1.0   \n",
      "3  0.166667  1.0  0.666667  0.339623  0.283105  0.0      0.0  0.885496    0.0   \n",
      "4  0.250000  0.0  0.333333  0.339623  0.178082  0.0      1.0  0.770992    0.0   \n",
      "\n",
      "    oldpeak  slope        ca  thal  target  \n",
      "0  0.370968    1.0  0.000000   0.5       0  \n",
      "1  0.241935    0.5  1.000000   0.0       1  \n",
      "2  0.419355    0.5  0.666667   1.0       1  \n",
      "3  0.564516    1.0  0.000000   0.0       0  \n",
      "4  0.225806    0.0  0.000000   0.0       0  \n",
      "           age      sex       cp  trestbps     chol      fbs  restecg  \\\n",
      "count  303.000  303.000  303.000   303.000  303.000  303.000  303.000   \n",
      "mean     0.530    0.680    0.719     0.356    0.276    0.149    0.495   \n",
      "std      0.188    0.467    0.320     0.166    0.118    0.356    0.497   \n",
      "min      0.000    0.000    0.000     0.000    0.000    0.000    0.000   \n",
      "25%      0.396    0.000    0.667     0.245    0.194    0.000    0.000   \n",
      "50%      0.562    1.000    0.667     0.340    0.263    0.000    0.500   \n",
      "75%      0.667    1.000    1.000     0.434    0.340    0.000    1.000   \n",
      "max      1.000    1.000    1.000     1.000    1.000    1.000    1.000   \n",
      "\n",
      "       thalach    exang  oldpeak    slope       ca     thal   target  \n",
      "count  303.000  303.000  303.000  303.000  303.000  303.000  303.000  \n",
      "mean     0.600    0.327    0.168    0.300    0.221    0.416    0.459  \n",
      "std      0.175    0.470    0.187    0.308    0.311    0.478    0.499  \n",
      "min      0.000    0.000    0.000    0.000    0.000    0.000    0.000  \n",
      "25%      0.477    0.000    0.000    0.000    0.000    0.000    0.000  \n",
      "50%      0.626    0.000    0.129    0.500    0.000    0.000    0.000  \n",
      "75%      0.725    1.000    0.258    0.500    0.333    1.000    1.000  \n",
      "max      1.000    1.000    1.000    1.000    1.000    1.000    1.000  \n",
      "\n",
      "The whole dataset:\n",
      "           age  sex        cp  trestbps      chol  fbs  restecg   thalach  \\\n",
      "0    0.708333  1.0  0.000000  0.481132  0.244292  1.0      1.0  0.603053   \n",
      "1    0.791667  1.0  1.000000  0.622642  0.365297  0.0      1.0  0.282443   \n",
      "2    0.791667  1.0  1.000000  0.245283  0.235160  0.0      1.0  0.442748   \n",
      "3    0.166667  1.0  0.666667  0.339623  0.283105  0.0      0.0  0.885496   \n",
      "4    0.250000  0.0  0.333333  0.339623  0.178082  0.0      1.0  0.770992   \n",
      "..        ...  ...       ...       ...       ...  ...      ...       ...   \n",
      "298  0.333333  1.0  0.000000  0.150943  0.315068  0.0      0.0  0.465649   \n",
      "299  0.812500  1.0  1.000000  0.471698  0.152968  1.0      0.0  0.534351   \n",
      "300  0.583333  1.0  1.000000  0.339623  0.011416  0.0      0.0  0.335878   \n",
      "301  0.583333  0.0  0.333333  0.339623  0.251142  0.0      1.0  0.786260   \n",
      "302  0.187500  1.0  0.666667  0.415094  0.111872  0.0      0.0  0.778626   \n",
      "\n",
      "     exang   oldpeak  slope        ca  thal  target  \n",
      "0      0.0  0.370968    1.0  0.000000   0.5       0  \n",
      "1      1.0  0.241935    0.5  1.000000   0.0       1  \n",
      "2      1.0  0.419355    0.5  0.666667   1.0       1  \n",
      "3      0.0  0.564516    1.0  0.000000   0.0       0  \n",
      "4      0.0  0.225806    0.0  0.000000   0.0       0  \n",
      "..     ...       ...    ...       ...   ...     ...  \n",
      "298    0.0  0.193548    0.5  0.000000   1.0       1  \n",
      "299    0.0  0.548387    0.5  0.666667   1.0       1  \n",
      "300    1.0  0.193548    0.5  0.333333   1.0       1  \n",
      "301    0.0  0.000000    0.5  0.333333   0.0       1  \n",
      "302    0.0  0.000000    0.0  0.000000   0.0       0  \n",
      "\n",
      "[303 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "first_heart_csv = \"Heart_disease_cleveland_new.csv\"\n",
    "df = pd.read_csv(first_heart_csv)\n",
    "X1 = df.iloc[:, :-1]\n",
    "y1 = df.iloc[:, -1]\n",
    "scaleMinMax_1 = MinMaxScaler(feature_range=(0, 1)) #normalize to value between 0 and 1\n",
    "X = scaleMinMax_1.fit_transform(X1)\n",
    "\n",
    "X1_normalized = pd.DataFrame(X, columns= X1.columns)\n",
    "X1_normalized['target'] = y1\n",
    "\n",
    "print(X1_normalized.head())\n",
    "print(X1_normalized.describe().round(3))\n",
    "X1_normalized.to_csv(\"heart_normalized.csv\", index=False)\n",
    "\n",
    "print(\"\\nThe whole dataset:\\n\", X1_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection & Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using RandomizedSearchCV for parameter calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age  sex        cp  trestbps      chol  fbs  restecg   thalach  exang  \\\n",
      "0  0.708333  1.0  0.000000  0.481132  0.244292  1.0      1.0  0.603053    0.0   \n",
      "1  0.791667  1.0  1.000000  0.622642  0.365297  0.0      1.0  0.282443    1.0   \n",
      "2  0.791667  1.0  1.000000  0.245283  0.235160  0.0      1.0  0.442748    1.0   \n",
      "3  0.166667  1.0  0.666667  0.339623  0.283105  0.0      0.0  0.885496    0.0   \n",
      "4  0.250000  0.0  0.333333  0.339623  0.178082  0.0      1.0  0.770992    0.0   \n",
      "\n",
      "    oldpeak  slope        ca  thal  target  \n",
      "0  0.370968    1.0  0.000000   0.5       0  \n",
      "1  0.241935    0.5  1.000000   0.0       1  \n",
      "2  0.419355    0.5  0.666667   1.0       1  \n",
      "3  0.564516    1.0  0.000000   0.0       0  \n",
      "4  0.225806    0.0  0.000000   0.0       0  \n",
      "Number of rows and columns in train and test data  (242, 13) (61, 13)\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best Parameters Found: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_depth': 20}\n",
      "Predicted values (First five):  [0 1 1 1 1]\n",
      "Predicted Probabilities for the first 5 samples:\n",
      "[[0.71498291 0.28501709]\n",
      " [0.32592821 0.67407179]\n",
      " [0.17416292 0.82583708]\n",
      " [0.41808216 0.58191784]\n",
      " [0.18119736 0.81880264]]\n",
      "Accuracy: 0.9016\n",
      "Precision: 0.9333\n",
      "Recall: 0.8750\n",
      "F1: 0.9032\n",
      "THe Random Forest model has been saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "df1 = pd.read_csv(\"heart_normalized.csv\")\n",
    "print(df1.head())\n",
    "\n",
    "# Split the input and output\n",
    "X1 = df1.drop(columns=[\"target\"])\n",
    "y1 = df1[\"target\"]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "print(\"Number of rows and columns in train and test data \", X_train.shape, X_test.shape)\n",
    "\n",
    "# RandomForestClassifier model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the parameter grid for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV to find the best parameters\n",
    "random_search = RandomizedSearchCV(estimator=rf_model, param_distributions=param_dist, n_iter=10, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# This does the randomized search process as well as calculates the best model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters from the random search\n",
    "best_params = random_search.best_params_\n",
    "print(f\"Best Parameters Found: {best_params}\")\n",
    "\n",
    "# Get the best model\n",
    "rf_model_updated = random_search.best_estimator_\n",
    "\n",
    "\n",
    "# Predict using the rf model\n",
    "y_pred_updated = rf_model_updated.predict(X_test)\n",
    "\n",
    "print(\"Predicted values (First five): \", y_pred_updated[:5])\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_updated)\n",
    "precision = precision_score(y_test, y_pred_updated)\n",
    "f1 = f1_score(y_test, y_pred_updated)\n",
    "recall = recall_score(y_test, y_pred_updated)\n",
    "\n",
    "# Get the predicted probabilities for the  model\n",
    "y_proba_updated = rf_model_updated.predict_proba(X_test)\n",
    "\n",
    "print(\"Predicted Probabilities for the first 5 samples:\")\n",
    "print(y_proba_updated[:5])\n",
    "\n",
    "# Evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1: {f1:.4f}\")\n",
    "\n",
    "# Save the updated model\n",
    "joblib.dump(rf_model_updated, 'random_forest_model_RandomizedSearchCV.pkl')\n",
    "print(\"THe Random Forest model has been saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using GridSearchCV for better parameter calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# This will take more time but we get better results. So keep this as seperate notebook cell.\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test input values:\n",
      "           age  sex        cp  trestbps      chol  fbs  restecg   thalach  \\\n",
      "179  0.500000  1.0  0.666667  0.339623  0.273973  1.0      1.0  0.778626   \n",
      "228  0.520833  1.0  1.000000  0.150943  0.182648  0.0      1.0  0.282443   \n",
      "111  0.562500  1.0  1.000000  0.292453  0.280822  1.0      1.0  0.557252   \n",
      "246  0.604167  1.0  1.000000  0.056604  0.246575  0.0      0.0  0.648855   \n",
      "60   0.458333  0.0  1.000000  0.339623  0.408676  0.0      0.0  0.541985   \n",
      "\n",
      "     exang   oldpeak  slope        ca  thal  \n",
      "179    0.0  0.000000    0.0  1.000000   0.0  \n",
      "228    1.0  0.000000    0.5  0.333333   0.0  \n",
      "111    1.0  0.193548    0.5  0.333333   0.0  \n",
      "246    0.0  0.016129    0.0  0.333333   1.0  \n",
      "60     1.0  0.193548    0.5  0.000000   1.0  \n",
      "Actual result values:\n",
      " 179    0\n",
      "228    1\n",
      "111    1\n",
      "246    1\n",
      "60     1\n",
      "Name: target, dtype: int64\n",
      "Predicted values (First five):  [0 1 1 1 1]\n",
      "Predicted Probabilities for the first 5 samples :\n",
      "[[0.678343   0.321657  ]\n",
      " [0.29140335 0.70859665]\n",
      " [0.15731085 0.84268915]\n",
      " [0.49666982 0.50333018]\n",
      " [0.1927132  0.8072868 ]]\n",
      "Accuracy: 0.9016\n",
      "Precision: 0.9333\n",
      "Recall: 0.8750\n",
      "F1: 0.9032\n",
      "Updated Random Forest model using GridSearchCV saved successfully.\n"
     ]
    }
   ],
   "source": [
    "rf_model_grid_search_updated = grid_search.best_estimator_\n",
    "y_pred_updated = rf_model_grid_search_updated.predict(X_test)\n",
    "\n",
    "print(\"The test input values:\\n\", X_test[:5])\n",
    "y_pred_updated = rf_model_updated.predict(X_test)\n",
    "\n",
    "print(\"Actual result values:\\n\", df1.loc[X_test.index[:5], \"target\"])\n",
    "\n",
    "print(\"Predicted values (First five): \", y_pred_updated[:5])\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_updated)\n",
    "precision = precision_score(y_test, y_pred_updated)\n",
    "f1 = f1_score(y_test, y_pred_updated)\n",
    "recall = recall_score(y_test, y_pred_updated)\n",
    "\n",
    "# Get the predicted probabilities for the updated model\n",
    "y_proba_updated = rf_model_grid_search_updated.predict_proba(X_test)\n",
    "\n",
    "# Print the predicted probabilities for the first few samples of the updated model\n",
    "print(\"Predicted Probabilities for the first 5 samples :\")\n",
    "print(y_proba_updated[:5])\n",
    "\n",
    "# Evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1: {f1:.4f}\")\n",
    "\n",
    "# Save the updated model if needed\n",
    "joblib.dump(rf_model_grid_search_updated, 'random_forest_model_GridSearchCV.pkl')\n",
    "print(\"Updated Random Forest model using GridSearchCV saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n",
      "Number of rows and columns in train and test data  (242, 13) (61, 13)\n",
      "The test input values (First five):\n",
      "           age  sex        cp  trestbps      chol  fbs  restecg   thalach  \\\n",
      "179  0.500000  1.0  0.666667  0.339623  0.273973  1.0      1.0  0.778626   \n",
      "228  0.520833  1.0  1.000000  0.150943  0.182648  0.0      1.0  0.282443   \n",
      "111  0.562500  1.0  1.000000  0.292453  0.280822  1.0      1.0  0.557252   \n",
      "246  0.604167  1.0  1.000000  0.056604  0.246575  0.0      0.0  0.648855   \n",
      "60   0.458333  0.0  1.000000  0.339623  0.408676  0.0      0.0  0.541985   \n",
      "\n",
      "     exang   oldpeak  slope        ca  thal  \n",
      "179    0.0  0.000000    0.0  1.000000   0.0  \n",
      "228    1.0  0.000000    0.5  0.333333   0.0  \n",
      "111    1.0  0.193548    0.5  0.333333   0.0  \n",
      "246    0.0  0.016129    0.0  0.333333   1.0  \n",
      "60     1.0  0.193548    0.5  0.000000   1.0  \n",
      "Actual result values:\n",
      " 179    0\n",
      "228    1\n",
      "111    1\n",
      "246    1\n",
      "60     1\n",
      "Name: target, dtype: int64\n",
      "Predicted values (First five):  [0 1 1 1 1]\n",
      "Accuracy: 0.8689\n",
      "Precision: 0.8750\n",
      "Recall: 0.8750\n",
      "F1: 0.8750\n",
      "The xgboost model has been saved successfully.\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x714d1cc79c60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x72ffafb71c60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x7be473b81c60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=150; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x7f2abff7dc60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=150; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=150; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x7f8f4ea71c60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x73b0fe67dc60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x709d7237dc60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=150; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x7788ce179c60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=150; total time=   0.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x72062897dc60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x74a718079c60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x7747fc479c60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=150; total time=   0.5s\n",
      "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x7e2a06579c60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 82, in __del__\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 91, in _stop\n",
      "  File \"/usr/lib/python3.13/multiprocessing/resource_tracker.py\", line 116, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"heart_normalized.csv\")\n",
    "x=df.drop(columns=['target'])\n",
    "y=df[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "print(\"Number of rows and columns in train and test data \",X_train.shape, X_test.shape)\n",
    "\n",
    "model = xgb.XGBClassifier(\n",
    "    max_depth=5,\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"The test input values (First five):\\n\", X_test[:5])\n",
    "\n",
    "print(\"Actual result values:\\n\", df.loc[X_test.index[:5], \"target\"])\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Predicted values (First five): \", y_pred[:5])\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1: {f1:.4f}\")\n",
    "\n",
    "\n",
    "joblib.dump(rf_model_grid_search_updated, 'xgboost_model.pkl')\n",
    "print(\"The xgboost model has been saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Say Global",
   "language": "python",
   "name": "global_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
